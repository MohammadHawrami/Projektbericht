% Vorlage für Praktikumsberichte
%
% Einleitung.tex
%
% Einleitung mit Vorstellung Unternehmen, Motivation und Bewerbungsprozess

\section{Einleitung}


\subsection{Woche 1 - Das Onboarding}
An meinem ersten Tag habe ich mich zunächst mit meinem Manager im Foyer des
Gebäudes WDF04 getroffen. Nach dem Treffen bekam ich direkt im Gebäude
WDF03 meine Zugangskarte, um Zutritt zu den Gebäuden zu haben. Anschließend
gingen wir zur IT-Abteilung, wo ich mein Equipment erhielt und meinen Laptop vor
Ort einrichtete. Besonderes Augenmerk lag dabei auf der Einrichtung des VPNs
sowie weiterer wichtiger Einstellungen für SAP.
Nachdem ich alles Notwendige erhalten hatte, konnte ich direkt an einem Meeting
teilnehmen, in dem besprochen wurde, welche Ziele für das Jahr 2025 vorgesehen
sind und in welchen Quartalen diese erreicht werden sollen. Im Anschluss fand ein
Daily-Meeting statt, in dem ich mich den Kollegen vorstellte, die an diesem Tag vor
Ort waren. Mir wurde direkt mitgeteilt, dass ich zunächst die Onboarding-Aufgaben
erledigen sollte, bevor ich mit meiner eigentlichen Tätigkeit beginnen könnte.
An meinem zweiten Tag bearbeitete ich zunächst die Onboarding-Aufgaben, um
anschließend mit den relevanten Aufgaben für mein Projekt beginnen zu können.
Danach hatte ich ein Gespräch mit meinem Betreuer, bei dem wir über Kubernetes
und Docker sprachen, um meinen Wissensstand zu überprüfen und eventuelle
Fragen zu klären. Am Ende des Gesprächs wurde mir mitgeteilt, dass ich in der
nächsten Woche an einem Hackathon teilnehmen werde, bei dem es um meine
Aufgabe geht. Dafür sollte ich mich näher mit dem Hyperspace-Portal und dem
Cloud Orchestrator beschäftigen.
Am Freitag setzte ich mein Lernen fort, wobei erste Schwierigkeiten auftraten. Mir
war zunächst nicht klar, wofür genau das Hyperspace-Portal benötigt wird und wie
es mit dem Cloud Orchestrator zusammenhängt. Ich besprach diese Fragen mit
meinem Betreuer, der sie mir verständlich erklärte. Dabei stellte ich fest, dass die
Dokumentation des Hyperspace-Portals sehr unklar und schwierig zu verstehen war,
was zu meinen Verständnisproblemen beitrug. Nachdem diese Schwierigkeiten
geklärt waren, beschäftigte ich mich intensiver mit dem Cloud Orchestrator.

\subsection{Woche 2 - Hackathon und Cloud Technologien}
Die zweite Woche meines Praktikums begann am Montag mit zusätzlichen
Oboarding-Aufgaben, die mir neue Einblicke in die Geschichte und
Unternehmensstruktur der SAP ermöglichten. Ich begleitete meinen Betreuer zum
Gebäude WDF13, wo ein von Hyperthon organisierter Hackathon stattfand. Zu
Beginn wurden 16 verschiedenen Problemstellungen vorgestellt, inklusive einer
ausführlichen Beschreibung und der Relevanz für das Unternehmen. Mein Betreuer
und Ich sind direkt zum Team mit dem Thema „GitOps Deployment with Cloud
Orchestrator“ gegangen, welche auch mein zukünftiges Thema für das Praktikum
sein wird. Wir begannen sofort, die Verbindung der Komponenten untereinander zu
analysieren, diese zu visualisieren und erstellten erste Elemente wie Kubernetes-
Cluster, Pipelines und Repositories.
Am Dienstag schloss ich die letzten verbleibenden Aufgaben meines Onboardings ab
und ging erneut zum Hackathon. Aufgrund fehlender Vorkenntnisse konnte ich zwar
nicht aktiv teilnehmen, nutzte jedoch die Gelegenheit, um parallel meine Kenntnisse
über den Cloud Orchestrator zu erweitern. Dies half mir, die Zusammenhänge
zwischen den Komponenten besser zu verstehen.
Am Mittwoch ging ich wieder zum Hackerthon, diesmal mit dem Fokus das wir einen
MCP (Managed Control Plane) anlegen. Diese Komponente ist entscheidend dafür,
den gewünschten Soll-Zustand kontinuierlich mit dem tatsächlichen Ist-Zustand der
Infrastuktur zu vergleichen und dadurch Probleme frühzeitig zu vermeiden.
Zufälligerweise war ich bei meiner eigenen Lernphase ebenfalls genau an diesem
Punkt angekommen. Ich versuchte eigenständig eine MCP anzulegen und erhielt
dabei Unterstützung vom Team, sodass ich das Prinzip dahinter besser
nachvollziehen konnte. Am Donnerstag, dem letzten Tag des Hackathons, wurden
die Ergebnisse der einzelnen Teams präsentiert. Ich konnte erfolgreich einen MCP
erstellen und begann anschließend mit einer Auffrischung von Docker und
Kubernetes, wobei ich mich zunächst mit Docker auseinandersetzte. Den
kompletten Freitag beschäftigte ich mich mit dem Lernen von Docker, um meine
grundlegenden Kenntnisse aufzufrischen und zusätzlich fortgeschrittene Kenntnisse
zu erlernen.

\subsection{Woche 3 - Vertiefung in Kubernetes und Crossplane und GitHub Actions}
Am Montag habe ich begonnen, mich mit Kubernetes auseinanderzusetzen. Neben
den grundlegenden Konzepten beschäftigte ich mich vor allem mit fortgeschrittenen
Themen, z. B. dem Umgang mit den Kubectl-Commands, der Anwendung von
Namespaces und YAML-Dateien auf einem Kubernetes-Cluster. Zusätzlich hatte ich
ein wöchentliches Meeting mit meinem Manager, in dem wir besprachen, wie es mir
aktuell im Praktikum geht, ob Schwierigkeiten aufgetreten sind und wie ich mein
Projekt persönlich einschätze.
Am Dienstag nahm ich an mehreren SAP-Onboarding-Meetings teil. In diesen
Meetings wurden verschiedene Themenbereiche behandelt, wie die verfügbaren
Mitarbeiter-Benefits, das Bestellen zusätzlicher Ausrüstung und der Security-Part
innerhalb der SAP. An diesem Tag fand zudem das wöchentliche Team-Planning statt,
an dem ich zum ersten Mal teilnahm. In diesem Planning wurden die Aufgaben für
die kommende Woche verteilt und der Status laufender Aufgaben besprochen.
Am Mittwoch folgte ein weiteres Onboarding-Meeting, in dem die allgemeinen
Abläufe innerhalb der SAP erläutert wurden, beispielsweise der Zugriff auf
Lohnabrechnungen oder das Vorgehen bei Krankheitsfällen. Anschließend
beschäftigte ich mich mit GitHub Actions, um grundlegende Kenntnisse über deren
Funktionsweise zu erlangen. Danach begann ich, mich in die Grundlagen von
Crossplane einzuarbeiten, um dessen Rolle und Funktionsweise besser zu
verstehen. Am Donnerstag setzte ich meine Arbeit mit Crossplane fort und versuchte
vor allem, die Verbindung zwischen Crossplane und dem Cloud Orchestrator zu
verstehen. Hierbei traten viele Verständnisprobleme auf. Deshalb vereinbarte ich für
den nächsten Tag ein Meeting mit meinem Betreuer, um ein Schaubild zu erstellen
und die Zusammenhänge besser zu verstehen.
Am Freitag ging ich nochmals alle Grundlagen zu Crossplane durch. Am Nachmittag
hatte ich dann ein Meeting mit meinem Betreuer, der unter anderem das Schaubild
erstellt hatte und mir zu dem noch z.B. die BTP, Crossplane etc. erklärt hat.

\subsection{Woche 4 - Crossplane, GitOps und GitHub Actions im Fokus}
Am Montag begann ich den Tag damit, eine To-do-Liste zu erstellen, um festzuhalten,
welche Kenntnisse mir noch fehlen, bevor ich mit meinem Projekt beginnen kann.
Anschließend bearbeitete ich den letzten Themenbereich von Crossplane und setzte
mich mit dem Aufbau und den Voraussetzungen für die Erstellung eines Providers
auseinander.
Am Dienstag nahm ich wieder am wöchentlichen Team-Planning teil, bei dem unter
anderem eine neue User Story besprochen wurde. Danach beschäftigte ich mich
erneut mit GitOps und GitHub Actions, da mir klar wurde, dass mein Verständnis
noch nicht vollständig war. Dabei ging ich genauer auf die grundlegenden Prinzipien
von GitOps ein, um besser nachvollziehen zu können, was genau darunter
verstanden wird. Parallel dazu sah ich mir ein Tutorial zu GitHub Actions an, das mir
half, zu verstehen, wie GitHub Actions genau funktioniert und was es mit Begriffen
wie z.B. Workflow und Job in diesem Zusammenhang auf sich hat.
Am Mittwoch und Donnerstag vertiefte ich meine Kenntnisse zu GitHub Actions.
Dabei legte ich den Fokus besonders auf die Unterschiede zwischen Arbeitsweisen
mit und ohne Continuous Integration (CI). Neben der theoretischen
Auseinandersetzung führte ich zahlreiche praktische Übungen durch, um meine
Kenntnisse zu festigen.
Am Freitag beendete ich schließlich das Kapitel zu GitHub Actions mit einigen
abschließenden Übungen.

\subsection{Woche 5 - Vertiefung in Flux, Piper und Cloud Foundry}
Am Montag begann ich mit einem neuen Thema und beschäftigte mich mit den
grundlegenden Funktionen und dem Verwendungszweck von Flux.
Am Dienstag nahm ich am wöchentlichen Team-Planning teil, bei dem die aktuellen
Aufgaben besprochen und neue Aufgaben verteilt wurden. Anschließend vertiefte ich
mein Wissen zu Flux und führte praktische Übungen durch, um den Workflow besser
zu verstehen. Dabei stieß ich jedoch auf technische Herausforderungen,
insbesondere bei der Verbindung meines Repos, da Flux standardmäßig auf
GitHub.com zugriff, anstatt auf GitHub.tools.sap. Mein Betreuer wies mich darauf
hin, dass ich explizit den korrekten Pfad angeben müsse, um solche Komplikationen
zu vermeiden. Ein weiterer Fehler trat bei der Generierung von Dateien auf, da statt
der erwarteten drei Dateien nur eine Datei erzeugt wurde, gefolgt von einem Timeout,
für das ich zunächst keine Lösung fand.
Mittwochs beschäftigte ich mich weiter mit Piper, einem Tool zur Erstellung von
Pipelines über das Hyperspace-Portal. Dabei setzte ich eine Pipeline auf und
untersuchte den Werkzeugkasten von Piper, um die Funktionsweise und Struktur der
SAP-Pipelines besser nachvollziehen zu können. Anschließend begann ich mit Cloud
Foundry und den grundlegenden Konzepten, einschließlich der Multi-Target
Application (MTA) und Multi-Target Application Archive (MTAR). Trotz anfänglicher
Schwierigkeiten gelang es mir schließlich, nach intensiver Recherche und
Unterstützung durch Kollegen, eine funktionierende Pipeline aufzusetzen.
Am Donnerstag konzentrierte ich mich nochmals auf MTAs und Cloud Foundry, da
mir ein tiefergehendes Verständnis noch fehlte. Besonders die Integration von Cloud
Foundry im Crossplane Provider interessierte mich. Außerdem hatte ich ein
ausführliches Meeting mit meinem Betreuer, in dem wir ein Workflow-Schaubild
erstellten und spezifische Details klärten. Ich versuchte auch, eine Verbindung
zwischen Cloud Foundry und der Business Technology Platform (BTP) herzustellen,
um einen Workspace zu erstellen, stieß dabei jedoch auf weitere technische
Schwierigkeiten.

\subsection{Woche 6 - Praktische Erfahrung und Fehleranalyse mit Crossplane Provider}
Am Dienstag startete ich mit dem wöchentlichen Team-Planning, in dem mein Betreuer die Ergebnisse aus dem Hackathon persäsentierte.
Anschließend ging ich erneut intensiv das Schaubild durch, um sicherzustellen, dass ich den Workflow vollständig verstanden hatte und um eventuelle Fragen direkt mit meinem Betreuer klären zu können.
Danach begann ich ein Go-TUtorial, um meine Kenntnisse aufzufrischen, was mir ermöglichte, besser mit dem Provider experimentieren und seine Funktionen verstehen zu können.
Währenddessen tauchten einige Verständnisprobleme bezüglich der Abläufe im Code und Workflow auf, die mein Betreuer mir jedoch verständlich erklären konnte.
Am Mittwoch nahm ich an einem weiteren Oboarding-Call teil, bei dem über anstehende Events informiert wurde und offene Fragen beantwortet wurden.
Danach beschäftigte ich mich mit dem Aufbau der MTA-Types, Secrets und der mta.yaml Dateien. 
Ich erstellte eine neue mta.yaml und einen neuen BTP-Space, stieß aber auf Probleme, weil ich die Credentials der mta.yaml verändert hatte, diese müssen jedoch mit denen der Haupt-MTA übereinstimmen.
Zudem debugte ich einige Methoden, um deren genauen Funktionsweise besser zu verstehen.
Den Donnertsag verbrachte ich intensiv damit, den Crossplane Provider zu testen und gezielt Fehler zu provozieren, um zu überprüfen, wie gut duese abgefangen werden.
Dabei entdeckte ich drei Bugs und konnte einen davon direkt beheben.
Den gesamten Freitag nutzte ich, um noch tiefer in den Provider einzutauchen, ihn besser zu verstehen und einen weiteren Bug erfolgreich zu lösen.

\subsection{Woche 7 - Erste Aufgaben um den Crossplane Cloud Foundry Provider weiterzuentwickeln}
Die Woche begann für mich am Montag aufgrund eines Feiertags und meines
Urlaubs als dreitägige Arbeitswoche. Zunächst nahm ich am monatlichen Release-
Review der SCM-Abteilung teil, an dem nicht nur Kollegen aus Walldorf, sondern
auch aus Ungarn und Indien beteiligt waren. In diesem Meeting präsentierten alle
Teilnehmer ihre geplanten Releases und stellten zudem neue Entwicklungen vor.
Danach setzte ich meine intensive Beschäftigung mit dem Crossplane Provider fort.
Dabei stieß ich jedoch an einigen Stellen auf Verständnisprobleme, insbesondere bei
komplexen Abläufen und Funktionen.
Am Dienstag nahm ich am wöchentlichen Team-Planning teil und arbeitete
anschließend weiter am Provider. Durch kontinuierliches Debuggen und Testen
verbesserte sich mein Verständnis für dessen Funktionsweise deutlich, sodass ich
die Abläufe zunehmend nachvollziehen konnte.
Am Mittwoch hatte ich ein ausführliches Treffen mit meinem Betreuer, der mir
detailliert den Unterschied zwischen Client und Controller im Kontext des Providers
erklärte. Danach erhielt ich meine erste konkrete Aufgabe zur Weiterentwicklung des
Providers, nämlich das Hinzufügen von drei neuen MTA-Parametern: AbortOnError,
VersionRule und Modules. Zusätzlich betrachteten wir den Terraform Provider, da
dieser eine ähnliche Struktur und Funktionsweise wie der Crossplane Cloud Foundry
Provider aufweist. Abschließend nahm ich an einem SAP IxP-Meeting teil, in dem das
Thema Projektmanagement behandelt wurde.

\subsection{Woche 8 - Weiterentwicklung des Providers und Fehleranalyse}
Diese Woche habe ich mit der Umsetzung meiner neuen Aufgabe begonnen, ich
musste drei MTA-Parameter im Crossplane Provider einfügen. Das Einfügen der
Parameter verlief zügig, doch bei der Fehlerbehandlung für den Parameter
AbortOnError trat ein unerwartetes Verhalten auf, mit dem ich mich den gesamten
Montag lang beschäftigte. Zusätzlich verursachte ein belegter Port ein kurzfristiges
Problem beim Start des Providers, das ich jedoch schnell beheben konnte.
Am Dienstag nahm ich am wöchentlichen Team-Planning teil, bei dem zwei neue
User Stories vorgestellt wurden. Ich setzte meine Arbeit an der Fehlerbehandlung
fort, blieb aber weiterhin ohne Lösung. Am Nachmittag nahm ich an meiner ersten
Scrum-Retrospektive teil. Dort wurden die Herausforderungen des letzten Sprints
diskutiert und neue Verbesserungen angestoßen.
Am Mittwoch hatte ich ein Meeting mit meinem Manager, bei dem ich meine offenen
Fragen ansprechen konnte. Die Fehlerbehandlung zu „AbortOnError” beschäftigte
mich weiterhin. Ich testete die beiden anderen Parameter manuell und stellte fest,
dass auch „VersionRule“ nicht wie gewünscht abbrach. Um dieses Problem zu
lösen, empfahl mir mein Betreuer, Kubebuilder zu verwenden, um nur bestimmte
Eingaben für den Parameter zu erlauben – ein Hinweis, der mir sehr weiterhalf.
Zusätzlich erledigte ich zwei HPOM-Onboarding-Aufgaben.
Am Donnerstag schloss ich fünf weitere Onboarding-Aufgaben ab. Danach arbeitete
ich erneut an „AbortOnError“, allerdings ohne Erfolg. Am Nachmittag überprüfte
mein Betreuer meine Implementierungen und wir entwickelten gemeinsam ein
neues Feature, das automatisch erkennt, wenn Module in einer MTA hinzugefügt
oder gelöscht werden.
Den Freitag begann ich mit einem Meeting über ein unerwünschtes Verhalten des
Cloud Orchestrators, der BTP-Spaces löschte. Anschließend beschäftigte ich mich
damit, wie man Tests in Go schreibt, um für die neuen MTA-Parameter Unit-Tests zu
erstellen.

\subsection{Woche 9 - Testentwicklung und Besprechung einer neuen Aufgabe}
Diese Woche stand ganz im Zeichen der Testentwicklung für die neu
implementierten MTA-Parameter im Crossplane Provider.
Am Montag widmete ich den gesamten Tag der Planung und Umsetzung
entsprechender Testfälle, die sicherstellen sollen, dass die Parameter korrekt
funktionieren. Am Nachmittag hatte ich ein Meeting mit einem Kollegen aus Berlin,
bei dem wir über die nächsten Schritte auf dem Weg zur Beta-Version sprachen.
Dabei zeichnete sich eine neue Aufgabe für mich ab, die ich jedoch zunächst mit
meinem Betreuer abstimmen wollte. Zudem schrieb ich erste Unit-Tests für die
neuen Parameter.
Am Dienstag nahm ich am wöchentlichen Team-Planning teil. Anschließend
arbeitete ich weiter an den Tests, stieß jedoch auf ein logisches Problem in einem
bestehenden Testfall, für das ich zunächst keine Lösung fand.
Auch am Mittwoch setzte ich meine Arbeit an den Tests fort. Ich überarbeitete
sämtliche Testfälle für die neuen MTA-Parameter, da die ursprüngliche Umsetzung
nicht den gewünschten Effekt erzielte. In einem Meeting mit Kollegen aus Berlin
besprachen wir die Vorgehensweise für meine neue Aufgabe zum Thema "Secret". Da
MTAs in der Regel in einer Maven- und nicht in einer Docker-Verzeichnisstruktur
laufen, entschieden wir uns gemeinsam mit meinem Betreuer dafür, zunächst mit
der Basic Authentication von Kubernetes zu arbeiten. Am Abend nahm ich an einem
Tech-Talk teil, bei dem das Thema MTA und der Crossplane Provider für Cloud
Foundry im Fokus stand.
Am Donnerstag hatte ich ein Treffen mit meinem hochschulseitigen Betreuer. Neben
dem Daily arbeitete ich weiterhin an der Optimierung der Tests. Auch am Freitag
setzte ich diese Arbeit fort. In einem Meeting mit einem Kollegen aus Berlin
besprachen wir Logikfehler in seinen Tests, die ich im Anschluss überarbeiten werde.

\subsection{Woche 10 - Testverbesserung und Umsetzung der Kubernetes Basic-Auth}
Diese Woche lag der Fokus erneut auf der Weiterentwicklug und Verbesserung der Tests sowie der Umsetzung meiner neuen
Aufgabe im Umgang mit Secrets im Kubernetes Cluster.
Am Montag nahm ich kurz an einem HPOM Workshop teil, entschied mich jedoch, mich lieber auf meine Aufgaben zu konzentrieren.
Den Großteil des Tages verbrachte ich damit, bestehende Tests zu überarbeiten und Fehler zu beheben.
Im Daily Meeting berichtete ich über den Fortschritt.
Die neue Aufgabe drehte sich draum, Secrets nicht mehr im Projekt abzulegen, sondern sicher im Kubernetes Cluster zu speichern.
Wir nutzen hierfür Basic Authentication, die im Wesentlichen über einen einzigen Commant mit Buntzername, Passwort und
Namespace funktioniert, um Zugriff auf das Artifactory zu erhalten.
Beim Versuch, eine Pull Request zu erstellen, stieß ich auf Probleme mit der Commit-Historie, die sich asl unterschiedlich
zu einem anderen Branch herausstellte.
Am Dienstag löschte ich daraufhin meinen Branch und erstellte ihn neu, um die Probleme mit der Historie zu beheben.
Anschließend konnte ich erfolgreich eine PR für die Tests der MTA-Parameter sowie einige Bugfixes einreichen.
Im wöchentlochen Team Planning besprachen wir die geplanten Releases für die kommenden Wochen.
Außerdem beschäftigte ich mich weiter mit meiner Aufgabe, analysierte den Aufbau der vorhandenen Docker Registry und vertiefte
mich in die Basic-Auth Umsetzung.
Zur Sicherheit holte ich mir Rückfragen bei einem Kollegen ein, um den Ablauf abzusichern
Mittwoch lag der Schwerpunkt weiterhin auf der Basic-Auth.
Ich erstellte den Command, umd die Secrets zu generieren und nahm Änderungen am Controller vor, indem wir jetzt Kubernetes
Konstanten anstelle von Strings verwenden.
Mittags fand ein Meeting zur Priorisierung der SCM-Abteilung im zweiten Halbjahr statt, gefolgt von einem Tech-Talk, in dem
zwei Kollegen über UI5 und die Verbindung mit GitHub Copilot berichteten.
Am Donnerstag schloss ich meine Aufgabe mit der Basic-Auth ab und testete gründlich, ob alles erwartugsgemäß funktioniert.
Dabei traten Probelme auf, etwas Fehler bei Jobs, die nicht als abgebrochen, sondern als Fehler makiert wurden, sowie eine
Inkonsistenz bei der MTA-Verfügbarkeit zwischen Cloud Foundry und dem BTP Space.
Nach einer Suche mit einem CF-Befehl konnte ich die fehlerhafte MTA löschen, sodass alles wieder ordnungsgemäß lief.
Zudem begann ich mit der Gliederung meines Projektberichts und präsentierte meine Ergebnisse einem Kollegen aus Berlin zur Abstimmung.
Freitag startete ich mit dem Daily Meeting in den Tag, erstellte die Pull Request für meine neue Aufgabe und arbeitete weiter
an der Gleiderung des Projektberichts sowie an weiteren Tests.

\subsection{Woche 11 - Fortschritte bei Secret-Implementierung und Testanpassung}
Da die Woche nur drei Arbeitstage umfasste, konzentrierte ich mich intensiv auf die Weiterentwicklung meiner aktuellen Aufgabe
sowie die Vorbereitung des Projektberichts.
Am Montag nahm ich am Relase Review teil, bei dem jede Abteilung ihre Neuerungen präsentierte, teilweise begleitet von Demos.
Zudem begann ich mit der ersten Gliederung für den Projektbericht, orientierte mich dabei an den Vorgaben von Herrn Leuchter
und holte mir Feedback von meinem Betreuer ein.
Außerdem überprüfte ich, welche Secret-Dateien aktuell verwendet werden, um später die passenden Parameter herauszufiltern.
Am Dienstag arbeitete ich weiter an der Umsetzung der Unterscheidung zwischen zwei Secret-Typen.
Am Nachmittag hatte ich ein Meeting mit einem Kollegen aus Berlin, um die Implementierung durchzugeen.
Meine Pull Request wurde ebenfalls reviewed und mit kleineren Verbesserungen akzeptiert.
Im langen Team Planning wurden zwei User Stories ausführlich besprochen, Aufgaben verteilt und Statusupdates gegeben.
Im Gespräch mit einem Kollegen klärte ich offene Fragen zu Kommentaren in Testmethoden und zeigte meine Implementierung.
Dabei stellte sich heraus, dass es bereits eine ähnliche Funktion zur Auslesung der Credentials gab, die ich nun adaptieren
und die Test entsprechen anpassen werde.
Am Mittwoch nahm ich an einem Daily und dem Employee Meeting teil, bei dem Updates zum Semesterplan und zum HPOM-Projekt
vorgestellt wurden.
Ich entschied mich, den Controller für das Parsen der MTA-JSON beizubehalten, das die alternative Version zu spezifisch für
Apps ist und zudem die bestehende Lösung funktioniert.
Anschließend passte ich die Tests an, um beide Secret arten, Basic-Auth und Docker Registry zu unterstützen.
Nach einem gefundenen Logikfehler im Code, den ich schnell behob, laufen die Tests jetzt wieder fehlerfrei.

\subsection{Woche 12 - Einrichtung des Cloud Orchestrators und erste Flux anbindung}
Woche 12 begann wie gewohnt mit dem Daily. Danach arbeitete ich weiter an den Tests für den Provider, konkret am TestObserve.
Trotz vieler Versuche konnte ich den Fehler nicht finden, auch mein Betreuer wusste zunächst nicht weiter.
Ein Kollege, der den test geschrieben hatte, konnte mir schließlich helfen, sodass das Problem gelöst werden konnte.
Die Änderungen habe ich am Dienstag gepusht.
Zusätzlich arbeitete ich an meinem JSON-Parser, der für das Docker Registry Secret notwendig ist, da dort Zugangsdaten im
JSON format enthalten sind.
Bestehende Parser deckten den MTA-Anwendungsfall nicht ab, daher war eine Anpassung nötig.
Wie jeden Dienstag fand das Team Planning statt, zu dem erhielt ich auch am Dienstag eine neue Aufgabe, den Cloud Orchestrator
für einen bestimmten BTP-Account aufzusetzen und dort testweise einen MTA zu deployen.
Beim Aufsetzen kam es zu Zugriffsproblemen, ich prüfte alle Konfigurationen, konnte den Fehler jedoch zunächst nicht finden.
Ein Call mit einem Kollegen brachte ebenfalls keine direkte Lösung.
Erste am Mittwochmorgen stellte sich heraus, dass der Fehler durch einen falsch gesetzeten Namespace verursacht wurde.
Im weiteren Verlauf hatte ich ein Meeting zum Thema Managed Controll Plane (MCP), bei dem ich erneut keinen Zugriff hatte.
Ein Kollege unterstütze mich beim Erstellen der MCP und bei der Beschaffung der zugehörigen kubeconfig.
Dabei wurde mir auch erklärt, dass es zwei verschiedene Konfigurationen gibt, eine für die Erstellung von Workspace, Project
und MCP und eine seperate für die Verbindung zur MCP selbst.
Anschließend connecte ich Flux mit der MCP.
Der erste Versuch schlug fehl, aber nach Korrektur eines Konfigurationsfehler funktionierte die Verbindung.
Danach wollte ich die MTA deployen, was erneut nicht funktionierte.
Zusammen mit einem Kollegen fand ich heraus, dass noch einige Komponenten fehlten.
Am Freitag setzte ich die Arbeit fort und konnte das Setup fast abschließen.
Zum Ende der Woche fand ein Gespärch mit meinem Manager statt, in dem ich den aktuellen Stand präsentierte und das weitere
Vorgehen besprochen wurde.

\subsection{Woche 13 - Fehlersuche und Fortschritte beim Cloud Orchestrator und MTA Deployment}
In dieser Woche, die aufgrund eines Feiertages nur vier Arbeitstage umfasste, arbeitete ich weiter am Cloud Orchestrator.
Am Dienstag fand wie gewohnt das Team Planning statt. Beim Aufsetzen des Orchestrators traten weiterhin Probleme auf, die
ich jedoch etwa eine Stunde vor Feierabend beheben konnte. Anschlißend versuchte ich, die MTA zu deployen, stieß dabei aber
auf einen unerklärlichen Fehler mit dem Statuscode 403 Forbidden.
Am Mittwoch konzentrierte ich mich wieder auf den Provider.
Um herauszufinden,warum das MTA Deployment in den BTP Space weiterhin nicht funktionierte, installierte ich eine Erweiterung,
um Logausgaben des Providers sichtbar zu machen.
Leider lieferten diese zunächst keinen hilfreichen Informationen.
Daher konnte ich schließlich Logs einsehen, jedoch enthielten sie keine aussagekräftige Fehlermeldung.
Daraufhin kontaktierte ich einen Kollegen aus dem Cloud Orchestrator Team mit der bitte, den Debug-Modus im Provider zu aktivieren.
Am Freitag konnte ich das Problem schließlich identifizieren, die Space ID des BTP-Spaces war veraltet, da der ursprüngliche
Space zwei Wochen zuvor gelöscht worden war.
Nach Aktualisierung der ID funktionierte das Deplyoment.
Zusätzlich erhielt ich noch Feedback von meinem Betreuer zu meiner Gliederung, das ich aufgenommen und entsprechen umgesetzt habe.

\subsection{Woche 14 - Fehlersuche, Vault ansätze und fortschritte im Cloud Orchestrator}
Die Woche begann wie gewohnt mit dem Daily.
Direkt danach nahm ich mir vor, weitere Tests mit der Managed Controll Plane (MCP) durchzuführen.
Beim Versuch, erneut einen MTA zu deployen, stellte ich fest, dass es dauerhaft fehlschlug.
Nach längerer Fehlersuche, dem Erstellen von zwei neuen MCPs und etwas ein bis zwei Studen Analyse fand ich den Grund, mein
GitHub Access Token war abgelaufen, was dazu führte, dass Flux und das Reconciling nicht mehr richtig funktionierten.
Beim Aktualisieren des Secrets kam es zu weiteren Problemen, sodass ich mehrmals ein neues Token erstellen und schließlich die
Änderungen direkt in OpenLens vornehmen musste.
Nach erfolgreicher Wiederherstellung der MCP hatte ich ein Meeting mit meinem Betreuer, in dem wir die nächsten Schritte
besprachen.
Dabei erhielt ich die Aufgabe, das Setup mit sauberer Benennung und in einem produktiv genutzten Space erneut durchzuführen.
Parallel dazu begann ich, micht mit HashCorp Vault zu beschäftigen insbesondere damit, wie sich Secret sicher verwalten lassen,
ohne sie ins Git Repository zu pushen.
Beim Testen stieß ich jedoch auf Zugriffsprobleme und entschied mich, vorerst beim bisherigen Ansatz zu bleiben, jedoch
nur einen Secret vorlage im Repository zu hinterlegen.
Ich gehe davon aus, dass Flux die Secrets direkt aus dem Cluster zieht, nicht aus dem Repository.
In einem Meeting mit den Kollegen aus Ungarn wurde zudem einen Java-Testbibliothek vorgestellt.
Später nahm ich an einer Info Session zur Durchführung von Bachelor- und Masterarbeiten teil, in der u. a. Verträge, Gehalt
und organisatorische Abläufe erklärt wurden.
Am Ende gab es eine offene Fragerunden für Werkstudenten und Praktikanten.
Zum Ende der Woche setzte ich meine Aufgabe fort, den Cloud Orchestratro für den SAP-EPD BTP-Account neu aufzusetzen, um die
MTAs im entsprechenden Space zu deployen.
Dabei traten kleinere Probleme auf, dich ich beheben konnte, bis mein kubectl in OpenLens plötzlich nicht mehr funktionierte,
was mich erneut ausbremste.
Am letzten Tag der Woche arbeitete ich daran weiter.

% Ende der Datei
